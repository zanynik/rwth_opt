{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gurobipy import *\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Booking_new.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-94628e9d457b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbooking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/Booking_new.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbd_zones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/BreakDownZones.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdz_to_bd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/DistanceMatrixDropZoneToBreakDownZone.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdrop_zones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/DropZones.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbu_zones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data/Outbound.xlsx\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'BU Zones'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, parse_cols, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     return io.parse(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, engine)\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Booking_new.xlsx'"
     ]
    }
   ],
   "source": [
    "booking = pd.read_excel(\"Data/Booking_new.xlsx\")\n",
    "bd_zones = pd.read_excel(\"Data/BreakDownZones.xlsx\")\n",
    "dz_to_bd = pd.read_excel(\"Data/DistanceMatrixDropZoneToBreakDownZone.xlsx\")\n",
    "drop_zones = pd.read_excel(\"Data/DropZones.xlsx\")\n",
    "bu_zones = pd.read_excel(\"Data/Outbound.xlsx\", sheet_name='BU Zones')\n",
    "bu_zones_workstations = pd.read_excel(\"Data/Outbound.xlsx\", sheet_name='WorkStation')\n",
    "bu_zones_to_flight = pd.read_excel(\"Data/Outbound.xlsx\", sheet_name='FlightNumber-BUZone')\n",
    "flight_default_processing = pd.read_excel(\"Data/Outbound.xlsx\", sheet_name='DefaultProcessingTime')\n",
    "flight_pre_processing = pd.read_excel(\"Data/Outbound.xlsx\", sheet_name='Pre-ProcessingBufferTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_pre_processing['Weekday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days_pre = flight_pre_processing[flight_pre_processing.Weekday=='*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days_pro = []\n",
    "for d in days:\n",
    "    for index, row in all_days_pre.iterrows():\n",
    "        all_days_pro.append((row['FlightNumber'], row['Weekday'], row['PreProcessingBufferTime'], d))\n",
    "\n",
    "all_days_pro1 = pd.DataFrame(all_days_pro, columns=('FlightNumber', 'Weekday', 'PreProcessingBufferTime', 'day'))\n",
    "all_days_pro1 = all_days_pro1.sort_values(by=['FlightNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_days_pre = flight_pre_processing[flight_pre_processing.Weekday==7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunday_days_pro = []\n",
    "for d in ['Sunday']:\n",
    "    for index, row in sunday_days_pre.iterrows():\n",
    "        sunday_days_pro.append((row['FlightNumber'], row['Weekday'], row['PreProcessingBufferTime'], d))\n",
    "\n",
    "sunday_days_pro1 = pd.DataFrame(sunday_days_pro, columns=('FlightNumber', 'Weekday', 'PreProcessingBufferTime', 'day'))\n",
    "sunday_days_pro1 = sunday_days_pro1.sort_values(by=['FlightNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturday_days_pre = flight_pre_processing[flight_pre_processing.Weekday==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saturday_days_pro = []\n",
    "for d in ['Saturday']:\n",
    "    for index, row in saturday_days_pre.iterrows():\n",
    "        saturday_days_pro.append((row['FlightNumber'], row['Weekday'], row['PreProcessingBufferTime'], d))\n",
    "\n",
    "saturday_days_pro1 = pd.DataFrame(saturday_days_pro, columns=('FlightNumber', 'Weekday', 'PreProcessingBufferTime', 'day'))\n",
    "saturday_days_pro1 = saturday_days_pro1.sort_values(by=['FlightNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_pre_processing_all = all_days_pro1.append(sunday_days_pro1)\n",
    "flight_pre_processing_all = flight_pre_processing_all.append(saturday_days_pro1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_pre_processing_all[['Pre_h','Pre_m','Pre_s']] = pd.DataFrame([(x.hour, x.minute, x.second) for x in flight_pre_processing_all['PreProcessingBufferTime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_pre_processing_all['flight_pre_id'] = flight_pre_processing_all['FlightNumber'].astype(str) + \"_\" + flight_pre_processing_all['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_pre_processing_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flight_default_processing[['default_h','default_m','default_s']] = pd.DataFrame([(x.hour, x.minute, x.second) for x in flight_default_processing['DefaultProcessingTime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu_zones_to_flight[['transport_dist_h','transport_dist_m','transport_dist_s']] = pd.DataFrame([(x.hour, x.minute, x.second) for x in bu_zones_to_flight['TransportationDistance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bu_zones_to_flight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu_zones_to_flight = bu_zones_to_flight.merge(flight_default_processing, on=['FlightNumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu_zones_to_flight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = list(drop_zones['Name'].unique())\n",
    "break_down_zones = list(bd_zones['Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_to_bd[['h','m','s']] = pd.DataFrame([(x.hour, x.minute, x.second) for x in dz_to_bd['TransportDuration']])\n",
    "bd_zones[['handling_h','handling_m','handling_s']] = pd.DataFrame([(x.hour, x.minute, x.second) for x in bd_zones['HandlingTimePerULD']])\n",
    "bd_zones[['transport_WH_h','transport_WH_m','transport_WH_s']] = pd.DataFrame([(x.hour, x.minute, x.second) for x in bd_zones['TransportationTimeToWH']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking['key_shipment_id_arrival_date'] = booking['Shipment ID'].astype(str) + booking['ShipmentArrivalDateUTC'].astype(str)\n",
    "booking = booking.drop_duplicates('key_shipment_id_arrival_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking = booking[booking.TotalWeight<=400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#Handling multiple ULDs having same number arriving less than 4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uld_number_times = booking[['ShipmentArrivalDateUTC', 'ArrivalULDNumber']]\n",
    "uld_number_times['id'] = booking['ShipmentArrivalDateUTC'].astype(str) + '_' + booking['ArrivalULDNumber'].astype(str)\n",
    "uld_number_times = uld_number_times.drop_duplicates('id')\n",
    "uld_number_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uld_number_times['count_uld_number'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_uld_count_by_number = uld_number_times.groupby(['ArrivalULDNumber']).agg({\"count_uld_number\":\"count\"}).rename(columns={\"count_uld_number\":\"Count\"}).reset_index()\n",
    "multiple_uld_numbers = unique_uld_count_by_number[unique_uld_count_by_number.Count>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_uld_number_and_times = uld_number_times[uld_number_times['ArrivalULDNumber'].isin((multiple_uld_numbers['ArrivalULDNumber'].unique()))]\n",
    "multiple_uld_number_and_times = multiple_uld_number_and_times.sort_values(by=['ArrivalULDNumber', 'ShipmentArrivalDateUTC'])\n",
    "multiple_uld_number_and_times['arrival_time'] = pd.to_datetime(multiple_uld_number_and_times['ShipmentArrivalDateUTC'])\n",
    "multiple_uld_number_and_times['diff'] = multiple_uld_number_and_times.sort_values(by=['ArrivalULDNumber', 'arrival_time']).groupby('ArrivalULDNumber')['arrival_time'].diff()\n",
    "multiple_ULD_arriving_below_4_hours = list(multiple_uld_number_and_times[multiple_uld_number_and_times['diff'].notnull() & (multiple_uld_number_and_times['diff'] < pd.Timedelta(4, unit='h'))]['ArrivalULDNumber'].unique())\n",
    "booking = booking[~booking['ArrivalULDNumber'].isin(multiple_ULD_arriving_below_4_hours)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering shipments arriving after departure\n",
    "booking['Shipment_arrival_date_time'] = pd.to_datetime(booking['ShipmentArrivalDateUTC'])\n",
    "booking = booking[booking.ShipmentDepartureDateUTC != '2018-10-24T26:20:00']\n",
    "booking['Shipment_departure_date_time'] = pd.to_datetime(booking['ShipmentDepartureDateUTC'])\n",
    "booking['Shipment_duration'] = booking['Shipment_departure_date_time']-booking['Shipment_arrival_date_time']\n",
    "booking = booking[booking.Shipment_duration>pd.Timedelta(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking['count_shipments'] = 1\n",
    "multple_dropzone_check = booking.pivot_table(index=['ArrivalULDNumber', 'Shipment_arrival_date_time'], columns='DropZone', values= 'count_shipments').reset_index()\n",
    "multple_dropzone_check = multple_dropzone_check.fillna(0)\n",
    "multple_dropzone_check['Two_different_dropzones_check'] = multple_dropzone_check['DZ NML-1'] + multple_dropzone_check['DZ NRML-1'] + multple_dropzone_check['DZ NRML-2']\n",
    "unique_dropzone_check = multple_dropzone_check[multple_dropzone_check.Two_different_dropzones_check==1.0]\n",
    "two_drop_zones = multple_dropzone_check[multple_dropzone_check.Two_different_dropzones_check>1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_drop_zones['unique_id'] = two_drop_zones['ArrivalULDNumber'].astype(str) + '_' + (pd.to_timedelta(two_drop_zones['Shipment_arrival_date_time']).astype('timedelta64[m]').astype(int).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_to_bd['DropZoneName_filter'] = dz_to_bd['DropZoneName'].apply(lambda x: x.split('-')[0]).str[3:]\n",
    "dz_to_bd['bd_type1'] = dz_to_bd['BreakDownZoneName'].apply(lambda x: x.split(' ')[1])\n",
    "dz_to_bd.loc[dz_to_bd['BreakDownZoneName'] == 'B BD NRML-1', 'bd_type1'] = \"NRML-1\"\n",
    "dz_to_bd.loc[dz_to_bd['BreakDownZoneName'] == 'B BD NRML-2', 'bd_type1'] = \"NRML-2\"\n",
    "dz_to_bd['bd_type'] =  dz_to_bd['bd_type1'].apply(lambda x: x.split('-')[0])\n",
    "dz_to_bd['check'] = np.where(dz_to_bd['DropZoneName_filter']==dz_to_bd['bd_type'], 1, 0)\n",
    "dz_to_bd = dz_to_bd[dz_to_bd['check']==1]\n",
    "dz_to_bd = dz_to_bd[['BreakDownZoneName', 'DropZoneName', 'TransportDuration', 'h', 'm', 's']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_ship_data = booking[['DropZone','ArrivalULDNumber', 'ShipmentArrivalDateUTC']]\n",
    "dz_ship_data['unique_key'] =  dz_ship_data['DropZone'].astype(str) + '_' + dz_ship_data['ArrivalULDNumber'].astype(str) + '_' + dz_ship_data['ShipmentArrivalDateUTC'].astype(str)\n",
    "dz_ship_data = dz_ship_data.drop_duplicates('unique_key')\n",
    "dz_ship_data = dz_ship_data[['DropZone', 'ArrivalULDNumber', 'ShipmentArrivalDateUTC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uld_bd_data = pd.merge(dz_ship_data, dz_to_bd, left_on='DropZone', right_on='DropZoneName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uld_bd_data['key'] = uld_bd_data['DropZone'].astype(str) + '_' + uld_bd_data['ArrivalULDNumber'].astype(str) + '_' + uld_bd_data['ShipmentArrivalDateUTC'].astype(str) + '_' + uld_bd_data['BreakDownZoneName'].astype(str)\n",
    "uld_bd_data = uld_bd_data.drop_duplicates('key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uld_bd_data['Shipment_arrival_date_time'] = pd.to_datetime(uld_bd_data['ShipmentArrivalDateUTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting BU workstations count\n",
    "bu_workstation_count = bu_zones_workstations.groupby(['Name']).count().reset_index()\n",
    "bu_workstation_count.columns = ['Name', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu_zones_data = pd.merge(bu_zones_to_flight, bu_zones, left_on='BU Zone', right_on='Name')\n",
    "bu_zone_all = pd.merge(bu_zones_data, bu_workstation_count, left_on='BU Zone', right_on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu_zone_all[['handling_ULD_h','handling_ULD_m','handling_ULD_s']] = pd.DataFrame([(x.hour, x.minute, x.second) for x in bu_zone_all['HandlingTimePerULD']])\n",
    "bu_zone_all[['transport_WH_h','transport_WH_m','transport_WH_s']] = pd.DataFrame([(x.hour, x.minute, x.second) for x in bu_zone_all['TransportationTimeToWH']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating booking_new variable for future use\n",
    "booking['build_up_arrival_time'] =  booking['Shipment_arrival_date_time'] #+ np.timedelta64(2, 'h')\n",
    "booking['build_up_finish_time'] =  booking['Shipment_departure_date_time'] #- np.timedelta64(1, 'h')\n",
    "booking_new = booking[['Shipment ID','ProductName', 'Priority', 'DropZone', 'ArrivalULDNumber', 'Pieces', 'Weight', 'TotalWeight',\n",
    "         'FlightNumberDeparture', 'key_shipment_id_arrival_date', 'Shipment_arrival_date_time', 'Shipment_departure_date_time',\n",
    "         'Shipment_duration', 'build_up_arrival_time', 'build_up_finish_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_new = pd.merge(booking_new, bu_zone_all, left_on='FlightNumberDeparture', right_on='FlightNumber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_new[['ULD_handling_h','ULD_handling_m','ULD_handling_s']] = pd.DataFrame([(x.hour, x.minute, x.second) for x in booking_new['HandlingTimePerULD']])\n",
    "booking_new['arrival_date'] = booking_new['Shipment_arrival_date_time'].dt.normalize()\n",
    "booking_new['departure_date'] = booking_new['Shipment_departure_date_time'].dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame used in  BD zone\n",
    "#sample_shipments = booking_new.iloc[98:118,:]\n",
    "# sample_shipments = booking_new[booking_new['ArrivalULDNumber'].isin(list([34842, 34222, 92870, 21231, 49815, 51228, 59243]))]\n",
    "# sample_shipments = booking_new[booking_new['ArrivalULDNumber'].isin(list([34842, 34222, 92870]))]\n",
    "# sample_shipments = booking_new[booking_new['ArrivalULDNumber'].isin(list([34842, 34222,92870, 21231, 49815, 59243]))]\n",
    "# sample_shipments = booking_new[booking_new['ArrivalULDNumber'].isin(list([51228]))]\n",
    "sample_shipments = booking_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shipments['Shipment_duration_minutes'] = (sample_shipments['Shipment_duration'] / np.timedelta64(1, 'm')).astype(int)\n",
    "sample_shipments['Shipment_arrival_time_minutes'] = pd.to_timedelta(sample_shipments['Shipment_arrival_date_time']).astype('timedelta64[m]').astype(int)\n",
    "sample_shipments['Shipment_departure_time_minutes'] = pd.to_timedelta(sample_shipments['Shipment_departure_date_time']).astype('timedelta64[m]').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = sample_shipments[['DropZone','ArrivalULDNumber', 'Shipment_arrival_date_time', 'Shipment_duration_minutes','Shipment_arrival_time_minutes', 'Shipment_departure_time_minutes']]\n",
    "df_merge= pd.merge(uld_bd_data, new, on=['DropZone','ArrivalULDNumber', 'Shipment_arrival_date_time'])\n",
    "df_merge = df_merge.drop_duplicates('key')\n",
    "bd_capacity = bd_zones[['Name','NumberOfWorkstations', 'handling_m']]\n",
    "df_merge1 = df_merge.merge(bd_capacity, left_on='BreakDownZoneName', right_on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BD process needed to to be completed with in 60 minutes\n",
    "df_merge1['one_hour_duration'] = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge1['unique_id'] = df_merge1['ArrivalULDNumber'].astype(str) + '_' + df_merge1['Shipment_arrival_time_minutes'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_drop_zones_ULD_Numbers = list(two_drop_zones['unique_id'].unique())\n",
    "#two_drop_zones_ULD_Numbers = list(two_drop_zones[two_drop_zones['ArrivalULDNumber'].isin([34842, 34222, 92870, 21231, 49815, 51228, 59243])]['unique_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uld_uniqueid_list = list(df_merge1['unique_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArrivalULDNumber_list = list(df_merge1['ArrivalULDNumber'].unique())\n",
    "BreakDownZoneName_list = list(df_merge1['BreakDownZoneName'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "##################################################################################################################\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shipments['day_name'] = sample_shipments['departure_date'].apply(lambda x: dt.datetime.strftime(x, '%A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shipments['flight_pre_id'] = sample_shipments['FlightNumber'].astype(str) + '_' + sample_shipments['day_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shipments = sample_shipments.merge(flight_pre_processing_all, on=['flight_pre_id'] , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_shipments = sample_shipments.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shipments['Pre_m'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shipments['FlightNumber_y'] = sample_shipments['FlightNumber_y'].astype('int64')\n",
    "sample_shipments['Pre_h'] = sample_shipments['Pre_h'].astype('int64')\n",
    "sample_shipments['Pre_m'] = sample_shipments['Pre_m'].astype('int64')\n",
    "sample_shipments['Pre_s'] = sample_shipments['Pre_s'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shipments['new_departure_time'] = sample_shipments['Shipment_departure_time_minutes'] - sample_shipments['transport_dist_m'] - sample_shipments['default_m'] - sample_shipments['Pre_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shipments['Shipment_departure_time_minutes'] = sample_shipments['new_departure_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_new_BU = sample_shipments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_new_BU['shipment_ID'] = range(1, len(booking_new_BU) + 1)\n",
    "shipment_id_list = list(booking_new_BU['shipment_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_new_BU.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data used for BU process 'sample_shipments_bu'\n",
    "sample_shipments_bu = booking_new_BU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_shipments_bu['Shipment_departure_time_minutes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shipments_bu['unique_id'] = sample_shipments_bu['ArrivalULDNumber'].astype(str) + '_' + sample_shipments_bu['Shipment_arrival_time_minutes'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArrivalULDNumber_list = list(sample_shipments_bu['ArrivalULDNumber'].unique())\n",
    "filghts_list = list(sample_shipments_bu['FlightNumberDeparture'].unique())\n",
    "bu_zones_list = list(sample_shipments_bu['Name_x'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "#####################################################################################\n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datetime\n",
    "print(dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model('Full model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discretisation has been done based on each BD zone handling times\n",
    "x = {}\n",
    "for i in uld_uniqueid_list:\n",
    "    BreakDownZoneName_list1 = list(df_merge1[df_merge1.unique_id==i]['BreakDownZoneName'])\n",
    "    #print(BreakDownZoneName_list1)\n",
    "    for j in BreakDownZoneName_list1:\n",
    "        #print(int(i),str(j))\n",
    "        new_check = df_merge1[(df_merge1.unique_id==i) & (df_merge1.BreakDownZoneName==j)]\n",
    "        min_time = min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique()))\n",
    "        arr = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "            #print(arr,\"--\",i)\n",
    "        shipment_arrival_duation_minutes_loop = list(new_check['one_hour_duration'].unique())[0] #list(new_check['Shipment_duration_minutes'].unique())[0]\n",
    "        handling_minutes = list(new_check['handling_m'].unique())[0]\n",
    "            #print(shipment_arrival_time_minutes_loop, handling_minutes)\n",
    "        t_start = (min_time + (math.ceil((arr-min_time)/handling_minutes)*handling_minutes))\n",
    "            #print(arr,\"-----\",t_start)\n",
    "        #if(i == '51228_25671360'):   \n",
    "            #print(t_start)\n",
    "        for k in range(t_start, t_start+shipment_arrival_duation_minutes_loop, handling_minutes):\n",
    "            x[i,j,k] = model.addVar(vtype=GRB.BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = {}\n",
    "for i in ArrivalULDNumber_list:\n",
    "    shipment_date_list = list(sample_shipments_bu[sample_shipments_bu.ArrivalULDNumber==i]['departure_date'].unique())\n",
    "    for d in shipment_date_list:\n",
    "        shipment_list = list(sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.departure_date==d)]['shipment_ID'])\n",
    "        #print(shipment_list)\n",
    "        for l in shipment_list:\n",
    "        #print(int(i),str(j))\n",
    "            number_of_ws = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Count'].unique()[0]\n",
    "            shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "            for m in range(1,number_of_ws+1):\n",
    "                for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop):\n",
    "                    z[l,m,t] = model.addVar(vtype=GRB.BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = {}\n",
    "for k in filghts_list:\n",
    "    shipment_date_list = list(sample_shipments_bu[sample_shipments_bu.FlightNumberDeparture==k]['departure_date'].unique())\n",
    "    for d in shipment_date_list:\n",
    "        ws_list = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['Count'].unique()[0]\n",
    "        shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "    #print(shipment_list)\n",
    "        for m in range(1, ws_list+1):\n",
    "        #print(int(i),str(j))\n",
    "            for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop):\n",
    "                q[k,m,t] = model.addVar(vtype=GRB.BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BD Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Handling time of each bd zone take into account for the quicksum\n",
    "for i in (list(set(uld_uniqueid_list) - set(two_drop_zones_ULD_Numbers))):\n",
    "    BreakDownZoneName_list1 = list(df_merge1[df_merge1.unique_id==i]['BreakDownZoneName'])\n",
    "    new_check = df_merge1[(df_merge1.unique_id==i)]\n",
    "    arr = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "    shipment_arrival_duation_minutes_loop = list(new_check['one_hour_duration'].unique())[0] #list(new_check['Shipment_duration_minutes'].unique())[0]\n",
    "    #min_time = min(list(df_merge1[df_merge1.BreakDownZoneName.isin(BreakDownZoneName_list1)]['Shipment_arrival_time_minutes'].unique()))\n",
    "    #t_start = shipment_arrival_time_minutes_loop + (handling_minutes - (shipment_arrival_time_minutes_loop%min_time))\n",
    "    if(len(BreakDownZoneName_list1)!=0):\n",
    "        model.addConstr(quicksum(x[i,b,c] for b in BreakDownZoneName_list1 for c in range((min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m'])) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Handling time of each bd zone take into account for the quicksum\n",
    "for i in two_drop_zones_ULD_Numbers:\n",
    "    #print(i)\n",
    "    BreakDownZoneName_list1 = list(df_merge1[df_merge1.unique_id==i]['BreakDownZoneName'])\n",
    "    bd_NML_list = [k for k in BreakDownZoneName_list1 if 'NML' in k]\n",
    "    bd_NRML_list = [k for k in BreakDownZoneName_list1 if 'NRML' in k]\n",
    "    #print(BreakDownZoneName_list1)\n",
    "    #print(bd_NML_list)\n",
    "    #print(bd_NRML_list)\n",
    "    new_check = df_merge1[(df_merge1.unique_id==i)]\n",
    "    arr = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "    #print(arr)\n",
    "    shipment_arrival_duation_minutes_loop = list(new_check['one_hour_duration'].unique())[0] #list(new_check['Shipment_duration_minutes'].unique())[0]\n",
    "    #min_time = min(list(df_merge1[df_merge1.BreakDownZoneName.isin(BreakDownZoneName_list1)]['Shipment_arrival_time_minutes'].unique()))\n",
    "    #t_start = shipment_arrival_time_minutes_loop + (handling_minutes - (shipment_arrival_time_minutes_loop%min_time))\n",
    "    if(len(bd_NML_list)!=0):\n",
    "        model.addConstr(quicksum(x[i,b,c] for b in bd_NML_list for c in range((min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m'])) == 1)\n",
    "    if(len(bd_NRML_list)!=0):\n",
    "        model.addConstr(quicksum(x[i,b,c] for b in bd_NRML_list for c in range((min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m'])) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precedence of NML before NRML\n",
    "for i in two_drop_zones_ULD_Numbers:\n",
    "    #print(i)\n",
    "    BreakDownZoneName_list1 = list(df_merge1[df_merge1.unique_id==i]['BreakDownZoneName'])\n",
    "    bd_NML_list = [k for k in BreakDownZoneName_list1 if 'NML' in k]\n",
    "    bd_NRML_list = [k for k in BreakDownZoneName_list1 if 'NRML' in k]\n",
    "    #print(BreakDownZoneName_list1)\n",
    "    #print(bd_NML_list)\n",
    "    #print(bd_NRML_list)\n",
    "    new_check = df_merge1[(df_merge1.unique_id==i)]\n",
    "    arr = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "    #print(arr)\n",
    "    shipment_arrival_duation_minutes_loop = list(new_check['one_hour_duration'].unique())[0] #list(new_check['Shipment_duration_minutes'].unique())[0]\n",
    "    #min_time = min(list(df_merge1[df_merge1.BreakDownZoneName.isin(BreakDownZoneName_list1)]['Shipment_arrival_time_minutes'].unique()))\n",
    "    #t_start = shipment_arrival_time_minutes_loop + (handling_minutes - (shipment_arrival_time_minutes_loop%min_time))\n",
    "    if((len(bd_NML_list)!=0) & (len(bd_NRML_list)!=0)):\n",
    "        model.addConstr(quicksum((c+(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*x[i,b,c] for b in bd_NML_list for c in range((min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m'])) <= quicksum(c*x[i,b,c] for b in bd_NRML_list for c in range((min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BD Assgnment Time constraint\n",
    "for i in (list(set(uld_uniqueid_list) - set(two_drop_zones_ULD_Numbers))):\n",
    "    #for j in BreakDownZoneName_list:\n",
    "        #print(int(i),str(j))\n",
    "    BreakDownZoneName_list1 = list(df_merge1[df_merge1.unique_id==i]['BreakDownZoneName'])\n",
    "    new_check = df_merge1[(df_merge1.unique_id==i)]\n",
    "    arr = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "    shipment_arrival_duation_minutes_loop = list(new_check['one_hour_duration'].unique())[0] #list(new_check['Shipment_duration_minutes'].unique())[0]\n",
    "    #arrival_time_each_uld = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "    transport_time_each_bd_zone = list(new_check['m'].unique())[0]\n",
    "    if(len(BreakDownZoneName_list1)!=0):\n",
    "        model.addConstr(quicksum((c-df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['m'])*x[i,b,c] for b in BreakDownZoneName_list1 for c in range((min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m'])) >= arr)\n",
    "        #for k in range(shipment_arrival_duation_minutes_loop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BD Assgnment Time constraint\n",
    "for i in two_drop_zones_ULD_Numbers:\n",
    "    #for j in BreakDownZoneName_list:\n",
    "        #print(int(i),str(j))\n",
    "    BreakDownZoneName_list1 = list(df_merge1[df_merge1.unique_id==i]['BreakDownZoneName'])\n",
    "    bd_NML_list = [k for k in BreakDownZoneName_list1 if 'NML' in k]\n",
    "    new_check = df_merge1[(df_merge1.unique_id==i)]\n",
    "    arr = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "    shipment_arrival_duation_minutes_loop = list(new_check['one_hour_duration'].unique())[0] #list(new_check['Shipment_duration_minutes'].unique())[0]\n",
    "    #arrival_time_each_uld = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "    transport_time_each_bd_zone = list(new_check['m'].unique())[0]\n",
    "    if(len(bd_NML_list)!=0):\n",
    "        model.addConstr(quicksum((c-df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['m'])*x[i,b,c] for b in bd_NML_list for c in range((min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((arr-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m'])) >= arr)\n",
    "        #for k in range(shipment_arrival_duation_minutes_loop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in BreakDownZoneName_list:\n",
    "        #print(int(i),str(j))\n",
    "    new_check = df_merge1[df_merge1.BreakDownZoneName==j]\n",
    "    min_time = min(list(new_check['Shipment_arrival_time_minutes'].unique()))\n",
    "    max_time = max(list(new_check['Shipment_departure_time_minutes'].unique()))\n",
    "    uld_break = list(new_check['unique_id'].unique())\n",
    "    #shipment_arrival_time_minutes_loop = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "    #shipment_arrival_duation_minutes_loop = list(new_check['one_hour_duration'].unique())[0] #list(new_check['Shipment_duration_minutes'].unique())[0]\n",
    "    handling_minutes = list(new_check['handling_m'].unique())[0]\n",
    "    #print(handling_minutes)\n",
    "    cap = list(new_check['NumberOfWorkstations'].unique())[0]\n",
    "    for t in range(min_time, max_time-handling_minutes-1, handling_minutes):\n",
    "        #print(t)\n",
    "        uld_list1=[]\n",
    "        for i in uld_break:\n",
    "            if(t in range((min_time + (math.ceil((new_check[new_check.unique_id==i].iloc[0]['Shipment_arrival_time_minutes']-min_time)/df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m'])*df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m'])), (min_time + (math.ceil((new_check[new_check.unique_id==i].iloc[0]['Shipment_arrival_time_minutes']-min_time)/df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m'])*df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))+shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m'])):#new_check[new_check.ArrivalULDNumber==i].iloc[0]['Shipment_departure_time_minutes'])): \n",
    "                uld_list1.append(i)\n",
    "                #print(t,uld_list1)\n",
    "        if(len(uld_list1)!=0):\n",
    "            model.addConstr(quicksum(x[a,j,t] for a in uld_list1) <= cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################################################################################################################\n",
    "##########################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BU Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in filghts_list:\n",
    "    shipment_date_list = list(sample_shipments_bu[sample_shipments_bu.FlightNumberDeparture==k]['departure_date'].unique())\n",
    "    for d in shipment_date_list:\n",
    "        shipment_list = list(sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['shipment_ID'])\n",
    "        ws_list = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['Count'].unique()[0]\n",
    "        shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "    #print(shipment_list)\n",
    "        for l in shipment_list:\n",
    "        #print(int(i),str(j))\n",
    "            if((len(shipment_list)!=0)):\n",
    "                model.addConstr(quicksum(z[l,m,t] for m in range(1, ws_list+1) for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop))==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in filghts_list:\n",
    "    shipment_date_list = list(sample_shipments_bu[sample_shipments_bu.FlightNumberDeparture==k]['departure_date'].unique())\n",
    "    for d in shipment_date_list:\n",
    "        shipment_list = list(sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['shipment_ID'])\n",
    "        ws_list = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['Count'].unique()[0]\n",
    "        shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "        bu_handling_time = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['handling_ULD_m'].unique()[0]\n",
    "        #print(bu_handling_time.dtype)\n",
    "    #print(shipment_list)\n",
    "        for m in range(1, ws_list+1):\n",
    "            for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop-bu_handling_time):\n",
    "                if((len(shipment_list)!=0)):\n",
    "                    model.addConstr(400*q[k,m,t] - quicksum(sample_shipments_bu[sample_shipments_bu.shipment_ID==l].iloc[0]['TotalWeight']*z[l,m,t] for l in shipment_list) \n",
    "                                >= quicksum(sample_shipments_bu[sample_shipments_bu.shipment_ID==l].iloc[0]['TotalWeight']*z[l,m,tau] for l in shipment_list for tau in range(t+1,t+bu_handling_time)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in filghts_list:\n",
    "    shipment_date_list = list(sample_shipments_bu[sample_shipments_bu.FlightNumberDeparture==k]['departure_date'].unique())\n",
    "    for d in shipment_date_list:\n",
    "        shipment_list = list(sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k)  & (sample_shipments_bu.departure_date==d)]['shipment_ID'])\n",
    "        ws_list = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k)   & (sample_shipments_bu.departure_date==d)]['Count'].unique()[0]\n",
    "        shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k)  & (sample_shipments_bu.departure_date==d)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "        bu_handling_time = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k)  & (sample_shipments_bu.departure_date==d)]['handling_ULD_m'].unique()[0]\n",
    "        if((len(shipment_list)!=0)):\n",
    "            model.addConstr(quicksum(q[k,m,t] for m in range(1, ws_list+1) for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop)) <= (quicksum(sample_shipments_bu[sample_shipments_bu.shipment_ID==l].iloc[0]['TotalWeight']*z[l,m,t] for l in shipment_list for t in range(shipment_departure_time_minutes_loop-60,shipment_departure_time_minutes_loop) for m in range(1, ws_list+1))/400) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in filghts_list:\n",
    "    shipment_date_list = list(sample_shipments_bu[sample_shipments_bu.FlightNumberDeparture==k]['departure_date'].unique())\n",
    "    for d in shipment_date_list:\n",
    "        bu_zone_for_flight = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['Name_x'].unique()[0]\n",
    "        othe_flights_df = sample_shipments_bu[(sample_shipments_bu.Name_x==bu_zone_for_flight) & (sample_shipments_bu.departure_date==d)]\n",
    "        ws_list = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['Count'].unique()[0]\n",
    "        shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "        other_flights = list(othe_flights_df[(othe_flights_df['FlightNumberDeparture'].isin([k]) == False) & (othe_flights_df.departure_date==d)]['FlightNumberDeparture'].unique())\n",
    "        bu_handling_time = sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==k) & (sample_shipments_bu.departure_date==d)]['handling_ULD_m'].unique()[0]\n",
    "        #print(k, \"----\",filghts_list,\"-------\", other_flights) \n",
    "        #print(shipment_list)\n",
    "        for m in range(1, ws_list+1):\n",
    "        #print(int(i),str(j))\n",
    "            for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop - bu_handling_time):\n",
    "                other_list  =[]\n",
    "                for i in other_flights:\n",
    "                    if(t in range((sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==i)].iloc[0]['Shipment_departure_time_minutes']-60),sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==i)].iloc[0]['Shipment_departure_time_minutes'])): \n",
    "                        other_list.append(i)\n",
    "                #print(k, \"----\",other_list)\n",
    "                if(len(other_list)!=0):\n",
    "                    model.addConstr(1-q[k,m,t] >= quicksum(q[p,m,ta] for p in other_list for ta in range(t,min(t+bu_handling_time,(sample_shipments_bu[(sample_shipments_bu.FlightNumberDeparture==p)].iloc[0]['Shipment_departure_time_minutes'])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (list(set(uld_uniqueid_list) - set(two_drop_zones_ULD_Numbers))):\n",
    "    BreakDownZoneName_list1 = list(df_merge1[df_merge1.unique_id==i]['BreakDownZoneName'])\n",
    "    shipment_date_list = list(sample_shipments_bu[sample_shipments_bu.unique_id==i]['departure_date'].unique())\n",
    "    for d in shipment_date_list:\n",
    "        shipment_list = list(sample_shipments_bu[(sample_shipments_bu.unique_id==i) & (sample_shipments_bu.departure_date==d)]['shipment_ID'])\n",
    "        #print(shipment_list)\n",
    "        for l in shipment_list:\n",
    "            number_of_ws = sample_shipments_bu[(sample_shipments_bu.unique_id==i) & (sample_shipments_bu.shipment_ID==l)]['Count'].unique()[0]\n",
    "            shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.unique_id==i) & (sample_shipments_bu.shipment_ID==l)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "            #shipment_arrival_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.unique_id==i) & (sample_shipments_bu.shipment_ID==l)]['Shipment_arrival_time_minutes'].unique()[0]\n",
    "            new_check = df_merge1[(df_merge1.unique_id==i)]\n",
    "            shipment_arrival_time_minutes_loop = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "            if((len(shipment_list)!=0)):\n",
    "                model.addConstr(quicksum(t*z[l,m,t] for m in range(1, ws_list+1) for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop)) >=\n",
    "                            quicksum((k + df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m'] + \n",
    "                                      df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['m'])*x[i,b,k] for b in BreakDownZoneName_list1 for k in range((min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((shipment_arrival_time_minutes_loop-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((shipment_arrival_time_minutes_loop-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m'])), name=\"Constraint 9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (two_drop_zones_ULD_Numbers):\n",
    "    BreakDownZoneName_list1 = list(df_merge1[df_merge1.unique_id==i]['BreakDownZoneName'])\n",
    "    bd_NRML_list = [k for k in BreakDownZoneName_list1 if 'NRML' in k]\n",
    "    shipment_date_list = list(sample_shipments_bu[sample_shipments_bu.unique_id==i]['departure_date'].unique())\n",
    "    for d in shipment_date_list:\n",
    "        shipment_list = list(sample_shipments_bu[(sample_shipments_bu.unique_id==i) & (sample_shipments_bu.departure_date==d)]['shipment_ID'])\n",
    "        #print(shipment_list)\n",
    "        for l in shipment_list:\n",
    "            number_of_ws = sample_shipments_bu[(sample_shipments_bu.unique_id==i) & (sample_shipments_bu.shipment_ID==l)]['Count'].unique()[0]\n",
    "            shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.unique_id==i) & (sample_shipments_bu.shipment_ID==l)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "            #shipment_arrival_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.unique_id==i) & (sample_shipments_bu.shipment_ID==l)]['Shipment_arrival_time_minutes'].unique()[0]\n",
    "            new_check = df_merge1[(df_merge1.unique_id==i)]\n",
    "            shipment_arrival_time_minutes_loop = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "            if((len(shipment_list)!=0)):\n",
    "                model.addConstr(quicksum(t*z[l,m,t] for m in range(1, ws_list+1) for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop)) >=\n",
    "                            quicksum((k + df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m'] + \n",
    "                                      df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['m'])*x[i,b,k] for b in bd_NRML_list for k in range((min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((shipment_arrival_time_minutes_loop-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((shipment_arrival_time_minutes_loop-min(list(df_merge1[df_merge1.BreakDownZoneName==b]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==b].iloc[0]['handling_m'])), name=\"Constraint Others\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = 0\n",
    "for i in ArrivalULDNumber_list:\n",
    "    shipment_date_list = list(sample_shipments_bu[sample_shipments_bu.ArrivalULDNumber==i]['departure_date'].unique())\n",
    "    for d in shipment_date_list:\n",
    "        shipment_list = list(sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.departure_date==d)]['shipment_ID'])\n",
    "    #print(shipment_list)\n",
    "        for l in shipment_list:\n",
    "        #print(int(i),str(j))\n",
    "            number_of_ws = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Count'].unique()[0]\n",
    "            shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "            if((len(shipment_list)!=0)):\n",
    "                obj += quicksum(t*z[l,m,t] for m in range(1,number_of_ws+1) for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.setObjective(obj, GRB.MINIMIZE)\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datetime\n",
    "print(dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.write('Full_Model_1.lp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in uld_uniqueid_list:\n",
    "    BreakDownZoneName_list1 = list(df_merge1[df_merge1.unique_id==i]['BreakDownZoneName'])\n",
    "    #print(i, \"in\", BreakDownZoneName_list1)\n",
    "    for j in BreakDownZoneName_list1:\n",
    "        #print(int(i),str(j))\n",
    "        new_check = df_merge1[(df_merge1.unique_id==i) & (df_merge1.BreakDownZoneName==j)]\n",
    "        shipment_arrival_time_minutes_loop = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "        shipment_arrival_duation_minutes_loop = list(new_check['one_hour_duration'].unique())[0] #list(new_check['Shipment_duration_minutes'].unique())[0]\n",
    "        for k in range((min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((shipment_arrival_time_minutes_loop-min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((shipment_arrival_time_minutes_loop-min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']):\n",
    "            if x[i,j,k].x > 0.5:\n",
    "                print(\"ULD\", i, \"assigned to BD\", j, \"at\", k)\n",
    "                #print(k)\n",
    "            #if(i == '51228_25671360'):\n",
    "                #print(x)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize the optimal assignment\n",
    "for i in uld_uniqueid_list:\n",
    "    BreakDownZoneName_list1 = list(df_merge1[df_merge1.unique_id==i]['BreakDownZoneName'])\n",
    "    for j in BreakDownZoneName_list1:\n",
    "        #print(int(i),str(j))\n",
    "        new_check = df_merge1[(df_merge1.unique_id==i) & (df_merge1.BreakDownZoneName==j)]\n",
    "        shipment_arrival_time_minutes_loop = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "        shipment_arrival_duation_minutes_loop = list(new_check['one_hour_duration'].unique())[0] #list(new_check['Shipment_duration_minutes'].unique())[0]\n",
    "        for k in range((min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((shipment_arrival_time_minutes_loop-min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((shipment_arrival_time_minutes_loop-min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']):\n",
    "            if x[i,j,k].x > 0.5:\n",
    "                #print(k)\n",
    "                #print(\"DZ\", i, \"assigned to BD\", j, \"at\", (shipment_arrival_time_minutes_loop+k))\n",
    "                plt.plot(k, j, \"o\")\n",
    "                #plt.annotate(i, (k,j))\n",
    "# for j in range(m):    \n",
    "#     plt.plot(1, j, \"o\")\n",
    "# for i in range(n):\n",
    "#     for j in range(m):\n",
    "#         if x[i,j].x > 0.5:\n",
    "#             plt.plot([0,1], [i,j], \"k\")# todo\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in ArrivalULDNumber_list:\n",
    "    shipment_list = list(sample_shipments_bu[sample_shipments_bu.ArrivalULDNumber==i]['shipment_ID'])\n",
    "    #print(shipment_list)\n",
    "    for l in shipment_list:\n",
    "        #print(int(i),str(j))\n",
    "        number_of_ws = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Count'].unique()[0]\n",
    "        shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "        for m in range(1,number_of_ws+1):\n",
    "            for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop):\n",
    "                if z[l,m,t].x > 0.5:\n",
    "                    print(\"Shipment\", l, \"assigned to WS\", m, \"at\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in ArrivalULDNumber_list:\n",
    "    shipment_list = list(sample_shipments_bu[sample_shipments_bu.ArrivalULDNumber==i]['shipment_ID'])\n",
    "    #print(shipment_list)\n",
    "    for l in shipment_list:\n",
    "        #print(int(i),str(j))\n",
    "        number_of_ws = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Count'].unique()[0]\n",
    "        shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "        bu_zone_name = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Name_x'].unique()[0]\n",
    "        flight_number = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['FlightNumberDeparture'].unique()[0]\n",
    "        for m in range(1,number_of_ws+1):\n",
    "            for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop):\n",
    "                if z[l,m,t].x > 0.5:\n",
    "                    k = str(bu_zone_name +\"-WS-\" + str(m))\n",
    "                    #print(\"Shipment\", l, \"assigned to\", bu_zone_name,\"WS\",m, \"at\", t)\n",
    "                    plt.plot(t, k, \"o\")\n",
    "                    #plt.annotate(l, (t,k))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################################################\n",
    "#################################################################################################################################\n",
    "#################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_x = []\n",
    "for i in uld_uniqueid_list:\n",
    "    BreakDownZoneName_list1 = list(df_merge1[df_merge1.unique_id==i]['BreakDownZoneName'])\n",
    "    #print(i, \"in\", BreakDownZoneName_list1)\n",
    "    for j in BreakDownZoneName_list1:\n",
    "        #print(int(i),str(j))\n",
    "        new_check = df_merge1[(df_merge1.unique_id==i) & (df_merge1.BreakDownZoneName==j)]\n",
    "        shipment_arrival_time_minutes_loop = list(new_check['Shipment_arrival_time_minutes'].unique())[0]\n",
    "        shipment_arrival_duation_minutes_loop = list(new_check['one_hour_duration'].unique())[0] #list(new_check['Shipment_duration_minutes'].unique())[0]\n",
    "        for k in range((min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((shipment_arrival_time_minutes_loop-min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))), (min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())) + (math.ceil((shipment_arrival_time_minutes_loop-min(list(df_merge1[df_merge1.BreakDownZoneName==j]['Shipment_arrival_time_minutes'].unique())))/(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))*(df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']))) +shipment_arrival_duation_minutes_loop, df_merge1[df_merge1.BreakDownZoneName==j].iloc[0]['handling_m']):\n",
    "            if x[i,j,k].x > 0.5:\n",
    "                df_final_x.append((i, j, k))\n",
    "\n",
    "\n",
    "df_final_x1 = pd.DataFrame(df_final_x, columns=('unique_id', 'bd_name', 'assigned_time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_x1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_x1.to_csv(r'bd_assigned_time_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_z = []\n",
    "for i in ArrivalULDNumber_list:\n",
    "    shipment_list = list(sample_shipments_bu[sample_shipments_bu.ArrivalULDNumber==i]['shipment_ID'])\n",
    "    #print(shipment_list)\n",
    "    for l in shipment_list:\n",
    "        #print(int(i),str(j))\n",
    "        number_of_ws = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Count'].unique()[0]\n",
    "        shipment_departure_time_minutes_loop = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Shipment_departure_time_minutes'].unique()[0]\n",
    "        bu_zone_name = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['Name_x'].unique()[0]\n",
    "        flight_number = sample_shipments_bu[(sample_shipments_bu.ArrivalULDNumber==i) & (sample_shipments_bu.shipment_ID==l)]['FlightNumberDeparture'].unique()[0]\n",
    "        for m in range(1,number_of_ws+1):\n",
    "            for t in range(shipment_departure_time_minutes_loop-60, shipment_departure_time_minutes_loop):\n",
    "                if z[l,m,t].x > 0.5:\n",
    "                    #k = str(bu_zone_name +\"-WS-\" + str(m))\n",
    "                    df_final_z.append((l,bu_zone_name ,m, t))\n",
    "\n",
    "df_final_z = pd.DataFrame(df_final_z, columns=('shipment_id', 'bu_name', 'ws_number', 'buildup_time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_z.to_csv(r'bu_workstation_time_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_shipments.to_csv(r'sample_shipments.csv')\n",
    "sample_shipments_bu.to_csv(r'sample_shipments_bu.csv')\n",
    "booking_new.to_csv(r'booking_new.csv')\n",
    "booking_new_BU.to_csv(r'booking_new_BU.csv')\n",
    "df_merge1.to_csv(r'df_merge1.csv')\n",
    "two_drop_zones.to_csv(r'two_drop_zones.csv')\n",
    "new.to_csv(r'new.csv')\n",
    "bu_zone_all.to_csv(r'bu_zone_all.csv')\n",
    "uld_bd_data.to_csv(r'uld_bd_data.csv')\n",
    "bu_workstation_count.to_csv(r'bu_workstation_count.csv')\n",
    "uld_bd_data.to_csv(r'uld_bd_data.csv')\n",
    "dz_ship_data.to_csv(r'dz_ship_data.csv')\n",
    "dz_to_bd.to_csv(r'dz_to_bd.csv')\n",
    "multiple_uld_number_and_times.to_csv(r'multiple_uld_number_and_times.csv')\n",
    "unique_uld_count_by_number.to_csv(r'unique_uld_count_by_number.csv')\n",
    "flight_pre_processing_all.to_csv(r'flight_pre_processing_all.csv')\n",
    "flight_default_processing.to_csv(r'flight_default_processing.csv')\n",
    "uld_number_times.to_csv(r'uld_number_times.csv')\n",
    "bu_zones_to_flight.to_csv(r'bu_zones_to_flight.csv')\n",
    "bd_zones.to_csv(r'bd_zones.csv')\n",
    "bd_capacity.to_csv(r'bd_capacity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
